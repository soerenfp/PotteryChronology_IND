---
title: "INDPotteryChronology_Statistics on vesssel size clustering"
author: "Soren Pedersen"
date: "20/09/2024"
output: html_document
---

###This document explores the standard descriptive statistics of the vessel forms

To better understand my data I have made a document to explore the data.

- Make a simple boxplot of how many data points you have for each vessel category (DONE)
- Make a boxplot of rim categories
- Make a boxplot of base categories

- Make a boxplot of which rim category are most used compared to the form

#ToDo!!!

- Make a principal component analysis between the "width" and "vessel type" to see whether some types have smaller or larger sizes. Or perhaps try this with the square cm2?
- Make a principal component analysis of the "orifice" and the vessel type
- Make a principal component analysis of the height and the vessel type


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Set up folder sturcture

```{r, echo=TRUE}

#install devtools

#install.packages("devtools")
library(devtools)

#install.packages("rrtools")
library(rrtools)

#You need the "remotes" package to install the "rrtools:BenMarwick" package 

#install.packages("remotes")
library(remotes)

remotes::install_github("benmarwick/rrtools")

#NOTE: I did install ALL updates

#devtools::install_github("benmarwick/rrtools")
---------------------------------------------------------------------------------------
  
#Create a new .Rproj -> very important not to have spaces, underscores or numbers in the folder name
  
#OBS: do not make a new .Rproj if you already have a project running -> skip to next step

#rrtools::use_compendium("C:/Users/Pedersen/Documents/R/PotteryChronologyIND")

#rrtools::use_compendium("C:/Users/Pedersen/Documents/R/RSeminar")


#Example: rrtools::use_compendium("C:/your/path/name/here/YourNewRProjectNameHere")

```

#Set up folder structure

This is to create folder "analysis" with sub-folder structure -> VERY USEFUL

The structure is made by Ben Marwick and is designated for archaeological writing and structure

```{r, echo=TRUE}
#Package that includes folder structure
library(rrtools)

#create folder -> creates the analysis folder and the structure
use_analysis()

#Do this below (pops-up when you execute use_analysis())

#Next, you need to:  ↓ ↓ ↓ ↓ 
#* Write your article/report/thesis, start at the paper.Rmd file
#* Add the citation style library file (csl) to replace the default provided here, see https://github.com/citation-style-language/
#* Add bibliographic details of cited items to the 'references.bib' file
#* For adding captions & cross-referencing in an Rmd, see https://bookdown.org/yihui/bookdown/
#* For adding citations & reference lists in an Rmd, see http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html
```

#Clean spreadsheet before loading into R

Cleaning a spreadsheet before loading it into R is an important step to ensure your data analysis is accurate and efficient. Here are some key steps you can follow to clean your spreadsheet:

1. Remove Unnecessary Data (done in excel sheet and r)
  - Delete Extra Rows/Columns: Remove any rows or columns that are not relevant to your analysis, such as empty rows or columns, headers that repeat, or any irrelevant metadata.
  - Trim Whitespace: Remove any leading or trailing spaces in your cells.

2. Standardize Formats (done in excel sheet)
  - Date Formats: Ensure all date entries are in a consistent format (e.g., YYYY-MM-DD).
  - Numeric Formats: Make sure numeric columns do not have any non-numeric characters (like commas or dollar signs).
  - Text Consistency: Standardize text entries (e.g., capitalization, spelling, etc.).

3. Handle Missing Values (done in r)
  - Identify Missing Values: Use functions to highlight or mark missing values.
  - Decide on a Strategy: Decide whether to remove rows with missing values, fill them in with a specific value (like the mean or median), or use other imputation techniques.

4. Correct Data Entry Errors (not done)
  - Identify Duplicates: Check for and remove duplicate rows if necessary.
  - Fix Inconsistencies: Look for typos or inconsistencies in categorical data (e.g., “male” vs. “Male”).

5. Transform Data if Necessary (not done)
  - Reformat Data Types: Ensure that each column has the correct data type (e.g., factors for categorical data, numeric for quantitative data).
  - Create New Columns: If necessary, create new columns for calculations or derived values.

6. Document Changes (done, see above parenthesis)
  - Keep a record of the changes made to your spreadsheet for transparency and reproducibility.

7. Save Your Cleaned Data (done, saved as .xlsx)
  - Save your cleaned spreadsheet in a compatible format (like CSV or Excel) for easy import into R.
  
8. I REMOVED THE 'SPECIAL' VESSEL TYPE CATEGORY AND REPLACED IT WITH '16a' INSTEAD IN THE 'data_tiral02_trimmed' DATA SET -> it was vessl number V559:    Ignore this data point when calculating vessel types
  
#Import excel file into a dataset and clean the dataset

Explanation of the Code:

- Loading Libraries: 
    Ensure that you have the required libraries installed and loaded.

- Reading Data: 
    The read_excel function is used to read the data from the Excel file.

- Data cleaning:
    Replace missing values with NAs
    Trim whitespaces in the excel sheet

- Saving Cleaned Data: 
    Optionally, save the cleaned dataset back to an Excel file using write.xlsx() from the openxlsx package (you'll need to install that package as well).

```{r, echo=TRUE}
# YOU CAN JUMP DIRECTLY TO STEP 1

### Load excel sheet into a dataset, trim whitespaces and replace missing rows with NAs

# Install necessary packages
#install.packages("readxl")
#install.packages("dplyr")
#install.packages("stringr")
#install.packages("tidyr")
#install.packages("openxlsx")

# Load necessary packages
#library(readxl)   # For reading Excel files
#library(dplyr)    # For data manipulation
#library(stringr)  # For string operations
#library(tidyr)    # For missing values operation
#library(openxlsx) # For writing Excel files

# Step 1: Load the Excel file
#data_trial02 <- read_excel("analysis/data/raw_data/timeline_data_trial02.xlsx")

# Step 2: View the initial structure of the data
#str(data_trial02)

# Step 3: Handle missing values
# Here, we're filling missing values with NA (default behavior)
# You can also replace them with specific values or remove rows.
#data_trial02 <- data_trial02 %>%
  #mutate(across(everything(), ~ replace_na(., NA)))  # Fill with NA (optional)

# Step 4: Trim whitespaces from all character columns
#data_trial02_trimmed <- data_trial02 %>%
  #mutate(across(where(is.character), ~ str_trim(.)))  # Trim whitespace

# View the cleaned data
#head(data_trial02_trimmed)

# Step 5: Save the cleaned data to a new Excel file
#write.xlsx(data_trial02_trimmed, "analysis/data/raw_data/data_trial02_trimmed.xlsx")

### Your dataset is now saved as "data_trial02_trimmed.xlsx" in the raw_data folder
```
Your dataset is now saved as "data_trial02_trimmed.xlsx" in the raw_data folder

### General thoughts ###

Just must make more descriptional statistics in are separate .rmd. Include the 'count of data points' below in a separate Rmd, and also include simple statistics as:

- which rim type is most popular?
- which base type is most popular?
- which form does most often have what which type of rim and base?
- Is there a popular vessel type for sites that are more influential? -> divide the sites into hubs and describe which are more influential than others!
- Which vessel type is most dominant pr. site?

# Count how many data points there are under each 'vessel type' category

STEP 1: Extract the three numerical categories into one spreadsheet and split the types so 1a becomes 1

```{r, echo=TRUE}

# Install and load necessary libraries
# install.packages("readxl")    # For reading Excel files
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("factoextra") # For visualizing clusters
# install.packages("cluster")

library(readxl)
library(dplyr)
library(ggplot2)
library(factoextra)
library(cluster)

# Load your dataset from an Excel file
# Replace 'your_file.xlsx' with the actual path to your file
ceramics_data <- read_excel("analysis/data/raw_data/data_trial02_trimmed.xlsx")

# Ensure your Excel file has columns: actual_diameter, actual_width, actual_height
# Check the first few rows of your data
#head(ceramics_data)

# Extract numeric part of type_category (e.g., "1a" becomes "1")
ceramics_data_typesplit <- ceramics_data %>%
  mutate(numeric_category = as.numeric(gsub("[^0-9]", "", `type_category`)))

# Select the relevant columns for clustering
ceramics_subset <- ceramics_data_typesplit %>%
  select(actual_diameter, actual_width, actual_height, numeric_category) %>%
  na.omit()  # Remove rows with missing values

# Standardize the data (important when variables have different units, still not sure if this is a good idea!!!)
#ceramics_scaled <- scale(ceramics_subset)
```

So, now I have created a dataset 'ceramics_subset' which contains the 'actual_diameter', 'actual_width', 'actual_height', and the new type category 'numeric_category' where my types are just named 1 instead of 1a 

# Boxplot of how many datapoints I have for each vessel type

```{r, echo=TRUE}
# Install and load libraries
# install.packages("ggplot2")  # Uncomment if you haven't installed ggplot2
# install.packages("cowplot")  # Uncomment if you haven't installed cowplot
library(ggplot2)
library(cowplot)

# Create a data frame to count the number of data points for each vessel type
vessel_counts <- data.frame(table(ceramics_subset$numeric_category))
colnames(vessel_counts) <- c("Vessel_Type", "Count")

# Create the boxplot with adjusted width
boxplot_plot <- ggplot(vessel_counts, aes(x = as.factor(Vessel_Type), y = Count)) +
  geom_boxplot(fill = "lightblue", outlier.color = "red") +
  labs(title = "Boxplot of Data Points per Vessel Type",
       x = "Vessel Type",
       y = "Number of Data Points") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for better visibility
    plot.margin = margin(10, 10, 10, 10)  # Adjust plot margins if needed
  )

# Legend table for vessel types
legend_table <- data.frame(
  Vessel_Type = 1:16,
  Description = c("Wide-open vessels", "Open vessels", "Closed horizontal-oval vessels", 
                  "Vertical vessels", "Closed vessels", "Tightly-closed vessels", 
                  "Open carinated vessels", "Wide-open carinated vessels", 
                  "Vertical-vertical oval vessels", "Closed-vertical oval vessels", 
                  "Tightly-closed vertical oval vessels", "Lids", 
                  "Flasks", "Bottles", "Tellem tripods", "Special")
)

# Convert the legend table to a plot with adjusted margins
legend_plot <- ggplot(legend_table, aes(x = "", y = Vessel_Type, label = paste(Vessel_Type, "=", Description))) +
  geom_text(hjust = 0, size = 3) +  # Reduced text size
  theme_void() +
  theme(
    plot.margin = margin(5, 100, 5, -60, "pt")  # Reduced right margin legend to move it closer to the plot
  )

# Arrange the boxplot and the legend side by side with adjusted widths
cowplot::plot_grid(boxplot_plot, legend_plot, ncol = 2, rel_widths = c(3, 3))  # Make the boxplot narrower adjusting rel_width

```
SO, the plot is not perfect (missing right margin), but I can adjust it later.

# PRELIM interpretation:

- Vessel category 5 (closed vessels) has by far the most data points -> interesting because it also has the most multi purpose function!!!
- 2nd most data point are vessel category 4 (vertical vessels) -> also interesting because I think this is also a very multi purpose vessel!!!
- 3rd most data point are vessel category 2 (open vessels)
- 4th most data point are vessel category 7 (Open carinated vessels)
- 5th most data point are vessel category 1 (wide-open vessels)
- 6th most data point are vessel category 15 (Tellem tripods)
- 7th and 8th most data point are vessel category 3 (closed horizontal-oval vessels) and 10 (closed vertical-oval vessels)
- 9th most data point are vessel category 6 (tightly-closed vessels)
- 10th most data point are vessel category 8 (wide-open carinated vessels)
- 11th most data point are vessel category 9 (Vertical vertical-oval vessels)
- 12th most data point are vessel category 11 (tightly-closed vertical oval vessels)
- 13th most data point are vessel category 14 (bottles)
- 14th most data point are vessel category 13 (flasks)
- vessel category 12 is left out because there are no data points (lids)

- There is actually a correlation between how "multi-purpose" a vessel is and the amount of data points I have collected. The "closed vessels", "vertical vessels" and the "open vessels" are the three categories you can describe as the most multi-purpose!

# Boxplot of how many datapoint I have per rim category

```{r, echo=TRUE}

# Load necessary package
library(ggplot2)

# Boxplot of 'Counts per Rim Category' 

ggplot(ceramics_data_typesplit, aes(x = rim_category)) +
  geom_bar() +
  labs(x = "Rim Category", y = "Count", title = "Counts per Rim Category") +
  theme_minimal()

```
So, this looks good! The NA category is from Karkarichinkat where the rim types were not presented. 

OBS: There is one type-o where I have some "TC" groups that should be "Tc" -> change that in the spreadsheet!

# PRELIM interpretation:

- The Sr (Simple Rounded) category is by far the most represented, as expected! Perhaps you can also say that this category is very multi-purpose because it does not include or exclude any functions?

- The Es (Everted Simple) category is the 2nd highest represented. This is also one of the earliest categories of rims (after the Sr, and 'thickened' categories). This rim category is for handling the vessel, to fasten a cloth and string around to close the vessel, or to pour from.

- The Otc (Outwards Thickened, curved) is the 3rd highest category and also the 2nd earliest rim type - if I remember correctly! This type is for handling the vessel (not hot vessel!), close the vessel with string and cloth, or to reinforce the rim.

- The Itc (Inwards Thickened, curved) is the 4th highest category. This category is also for handling the vessel or to reinforce the rim.

- The Sf (Simple, flattened) rim are the 5th highest category, and there is perhaps not so much function in this rim. Perhaps you can easier stack the vessels, but I think it is mosly for appearence. 

- The Oth (Outwards thickened, hinged) rims are the 6th highest category, and here the rim is for grabbing or reinforcing the vessel, but because it has a sharp corner under the rim then perhaps it is better suited for closing the vessel with cloth and string. This can also be an over-interpretation and the sharp corner under the rim can be just for aesthetics, or for a better grip?.

- The 7th and 8th highest categories are the Sb (Simple, beveled) and Sp (Simple, pointy) categories. I think these categories are mostly for aesthetics, but there can be some stacking functions in these

- the 9th highest category is the Tc (Thickened, curved) category, where this is for grapping or reinforcing the vessel. 

- The rest of the categories are quite evenly represented!

# Boxplot of how many datapoint I have per base category

```{r, echo=TRUE}

# Load necessary package
library(ggplot2)

# Boxplot of 'Counts per Base Category' 

ggplot(ceramics_data_typesplit, aes(x = base_category)) +
  geom_bar() +
  labs(x = "Base Category", y = "Count", title = "Counts per Base Category") +
  theme_minimal()

```
So, this looks nice !

#PRELIM interpretation:

- Most of the bases are NA because nothing was registered
- Bpe (Base, pedestalled) are the category with most data points -> in this category we also have the Tellem tripods base - perhaps I need to make a separate category for that!
- Br (Bases, ring) are the 2nd highest category
- Bf (Bases flat) are the 3rd highest category
- Bpo (Bases, pointy) are the 4th highest category
- Bl (Bases, legged) I think only has one count (jenne-jeno)
- Special -> I must find out what is the special category!

#ToDo:
- I think that I need to register whether the bases are rounded also. With this, I can see which form often has a round base and how the round bases correlate with the rims


### Exploring which "rim-category" is most often represented per "vessel_type" ###

To understand which rim_category is most often associated with each vessel_type, you can explore the relationship between the two categorical variables using several approaches, depending on the depth of analysis you're looking for.

Here are a few options:

#STEP 1: Contingency Table with Chi-Square Test of Independence

This test checks if there is a significant association between rim_category and vessel_type. A contingency table will show the counts of each combination of vessel_type and rim_category.

```{r, echo=TRUE}
# Create a contingency table
table_data_RimAndVessel <- table(ceramics_data_typesplit$numeric_category, ceramics_data_typesplit$rim_category)

# Perform the Chi-Square test of independence
chisq_test_RimAndVessel <- chisq.test(table_data_RimAndVessel)

# View the result
chisq_test_RimAndVessel

```
Interpretation (explained): If the p-value is small (typically < 0.05), it suggests a significant association between vessel_type and rim_category.

# PRELIM interpretation:

It looks like you've successfully run the Chi-Square test, and the results show a significant association between vessel_type and rim_category. Let's break down the output:

Results Interpretation:

X-squared = 1097.7: This is the test statistic for the Chi-Square test, indicating the strength of the association. Higher values suggest a stronger association.

df = 350: The degrees of freedom, which is calculated as (number of vessel_type categories - 1) * (number of rim_category categories - 1).

p-value < 2.2e-16: The p-value is extremely small (essentially 0), meaning that there is a statistically significant association between vessel_type and rim_category. In other words, the distribution of rim types is not independent of vessel types.

#STEP 2: Effect Size 

Since the Chi-Square test only tells you there is an association but not how strong it is, you can calculate Cramér's V to measure the strength of the association.

```{r, echo=TRUE}
# Install vcd package if you haven't already
#install.packages("vcd")
library(vcd)

# Calculate Cramér's V
cramers_v_RimAndVessel <- assocstats(table_data_RimAndVessel)
cramers_v_RimAndVessel
```
#PRELIM interpretation:

Key Results:

Likelihood Ratio (G²) = 404.17, p-value = 0.02411:
This statistic is another measure of association between vessel_type and rim_category. The p-value of 0.02411 suggests that the association is statistically significant, but less strong compared to the Pearson Chi-Square test.

Pearson Chi-Square (X²) = 1097.72, p-value = 0.00000:
This reiterates that the Pearson Chi-Square test found a very strong association between the two variables with a highly significant p-value (essentially zero).

Cramér's V = 0.362:
This is the measure of effect size. A value of 0.362 indicates a moderate association between vessel_type and rim_category.

Contingency Coefficient = 0.805:
This is another measure of association, which, like Cramér's V, suggests a strong association (values closer to 1 indicate a stronger association). However, Cramér's V is more commonly used for interpreting relationships in large contingency tables like yours.

The relationship between vessel_type and rim_category is statistically significant (as indicated by both the Pearson Chi-Square and Likelihood Ratio tests).

Cramér's V value of 0.362 shows that the association is moderate in strength. This suggests that there is some non-random relationship between the two variables, but it's not a very strong or overwhelming relationship.

# STEP 3: Mosaic plot

A visual way to explore the relationship is to use a mosaic plot, which visually represents the counts in a contingency table.

```{r, echo=TRUE}

# Create a mosaic plot
mosaicplot(table_data_RimAndVessel, main = "Mosaic Plot of Vessel Type and Rim Category", 
           xlab = "Vessel Type", ylab = "Rim Category", color = TRUE)

```

Let's try to make the mosaic plot more nice:

```{r, echo=TRUE}
# Adjust the plot window size for height
par(mai = c(1, 2, 0.5, 0.5))  # Adjust margins: bottom, left, top, right

# Create a mosaic plot with horizontal Y-axis labels and increased plot height
mosaicplot(table_data_RimAndVessel, 
           main = "Mosaic Plot of Vessel Type and Rim Category", 
           xlab = "Vessel Type", 
           ylab = "Rim Category", 
           color = TRUE, 
           las = 1,           # Make the Y-axis labels horizontal
           cex.axis = 0.4)    # Adjust the size of all axis labels

```
Ok, this looks ok, but I still need to adjust it a little bit. Larger axis labels and perhaps also a larger plot?

#PRELIM interpretation:

If I read the plot correctly.. I think that I need to understand how to better read it!

# Heatmap of correlations between Vessel type and Rim category

I make a heatmap to see if the plot is more ordered

```{r, echo=TRUE}
# Install required packages
#install.packages("reshape2")

# Load required packages
library(ggplot2)
library(reshape2)

# Convert the contingency table to a data frame for ggplot
df_table <- as.data.frame(table(table_data_RimAndVessel))

# Create a heatmap-like plot with ggplot
ggplot(df_table, aes(table_data_RimAndVessel, Freq, fill = Freq)) +
  geom_tile() +
  labs(x = "Vessel Type", y = "Rim Category", fill = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10), # Adjust X-axis labels
        axis.text.y = element_text(size = 10),  # Adjust Y-axis labels
        panel.grid.major = element_blank(),      # Remove grid lines
        panel.grid.minor = element_blank()) +    # Remove minor grid lines
  scale_fill_gradient(low = "lightblue", high = "darkblue")  # Adjust fill colors

```
This does not look right.. I must try to play around with it a bit more..

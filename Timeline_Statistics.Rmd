---
title: "INDPotteryChronology_Statistics"
author: "Soren Pedersen"
date: "20/09/2024"
output: html_document
---

###THIS IS THE MARKDOWN DOCUMENT OF THE STATISTICS OF THE IND POTTERY CHRONOLOGY
  #PhD thesis of Soren Feldborg


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Setup folder sturcture

```{r, echo=TRUe}

#install devtools

#install.packages("devtools")
library(devtools)

#install.packages("rrtools")
library(rrtools)

#You need the "remotes" package to install the "rrtools:BenMarwick" package 

#install.packages("remotes")
library(remotes)

remotes::install_github("benmarwick/rrtools")

#NOTE: I did install ALL updates

#devtools::install_github("benmarwick/rrtools")
---------------------------------------------------------------------------------------
  
#Create a new .Rproj -> very important not to have spaces, underscores or numbers in the folder name
  
#OBS: do not make a new .Rproj if you already have a project running -> skip to next step

#rrtools::use_compendium("C:/Users/Pedersen/Documents/R/PotteryChronologyIND")

#rrtools::use_compendium("C:/Users/Pedersen/Documents/R/RSeminar")


#Example: rrtools::use_compendium("C:/your/path/name/here/YourNewRProjectNameHere")

```

#Set up folder structure

This is to create folder "analysis" with sub-folder structure -> VERY USEFUL

The structure is made by Ben Marwick and is designated for archaeological writing and structure

```{r, echo=TRUE}
#Package that includes folder structure
library(rrtools)

#create folder -> creates the analysis folder and the structure
use_analysis()

#Do this below (pops-up when you execute use_analysis())

#Next, you need to:  ↓ ↓ ↓ ↓ 
#* Write your article/report/thesis, start at the paper.Rmd file
#* Add the citation style library file (csl) to replace the default provided here, see https://github.com/citation-style-language/
#* Add bibliographic details of cited items to the 'references.bib' file
#* For adding captions & cross-referencing in an Rmd, see https://bookdown.org/yihui/bookdown/
#* For adding citations & reference lists in an Rmd, see http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html
```

#Clean spreadsheet before loading into R

Cleaning a spreadsheet before loading it into R is an important step to ensure your data analysis is accurate and efficient. Here are some key steps you can follow to clean your spreadsheet:

1. Remove Unnecessary Data (done in excel sheet and r)
  - Delete Extra Rows/Columns: Remove any rows or columns that are not relevant to your analysis, such as empty rows or columns, headers that repeat, or any irrelevant metadata.
  - Trim Whitespace: Remove any leading or trailing spaces in your cells.

2. Standardize Formats (done in excel sheet)
  - Date Formats: Ensure all date entries are in a consistent format (e.g., YYYY-MM-DD).
  - Numeric Formats: Make sure numeric columns do not have any non-numeric characters (like commas or dollar signs).
  - Text Consistency: Standardize text entries (e.g., capitalization, spelling, etc.).

3. Handle Missing Values (done in r)
  - Identify Missing Values: Use functions to highlight or mark missing values.
  - Decide on a Strategy: Decide whether to remove rows with missing values, fill them in with a specific value (like the mean or median), or use other imputation techniques.

4. Correct Data Entry Errors (not done)
  - Identify Duplicates: Check for and remove duplicate rows if necessary.
  - Fix Inconsistencies: Look for typos or inconsistencies in categorical data (e.g., “male” vs. “Male”).

5. Transform Data if Necessary (not done)
  - Reformat Data Types: Ensure that each column has the correct data type (e.g., factors for categorical data, numeric for quantitative data).
  - Create New Columns: If necessary, create new columns for calculations or derived values.

6. Document Changes (done, see above parenthesis)
  - Keep a record of the changes made to your spreadsheet for transparency and reproducibility.

7. Save Your Cleaned Data (done, saved as .xlsx)
  - Save your cleaned spreadsheet in a compatible format (like CSV or Excel) for easy import into R.
  
#Import excel file into a dataset and clean the dataset

Explanation of the Code:

- Loading Libraries: 
    Ensure that you have the required libraries installed and loaded.

- Reading Data: 
    The read_excel function is used to read the data from the Excel file.

- Data cleaning:
    Replace missing values with NAs
    Trim whitespaces in the excel sheet

- Saving Cleaned Data: 
    Optionally, save the cleaned dataset back to an Excel file using write.xlsx() from the openxlsx package (you'll need to install that package as well).

```{r, echo=TRUE}
### Load excel sheet into a dataset, trim whitespaces and replace missing rows with NAs

# Install necessary packages
#install.packages("readxl")
#install.packages("dplyr")
#install.packages("stringr")
#install.packages("tidyr")
#install.packages("openxlsx")

# Load necessary packages
library(readxl)   # For reading Excel files
library(dplyr)    # For data manipulation
library(stringr)  # For string operations
library(tidyr)    # For missing values operation
library(openxlsx) # For writing Excel files

# Step 1: Load the Excel file
data_trial02 <- read_excel("analysis/data/raw_data/timeline_data_trial02.xlsx")

# Step 2: View the initial structure of the data
#str(data_trial02)

# Step 3: Handle missing values
# Here, we're filling missing values with NA (default behavior)
# You can also replace them with specific values or remove rows.
data_trial02 <- data_trial02 %>%
  mutate(across(everything(), ~ replace_na(., NA)))  # Fill with NA (optional)

# Step 4: Trim whitespaces from all character columns
data_trial02_trimmed <- data_trial02 %>%
  mutate(across(where(is.character), ~ str_trim(.)))  # Trim whitespace

# View the cleaned data
#head(data_trial02_trimmed)

# Step 5: Save the cleaned data to a new Excel file
write.xlsx(data_trial02_trimmed, "analysis/data/raw_data/data_trial02_trimmed.xlsx")

### Your dataset is now saved as "data_trial02_trimmed.xlsx" in the raw_data folder
```

#Make cluster analysis of the main "actural_width" category dependent on "type_category"

To analyze clusters of Actual width within each numeric category of the Type category (ignoring the letter part, such as 1a, 1b, 1c grouped as 1), we can split the data by the numeric portion of the Type category and then perform clustering on Actual width measurements within each group. Here’s how to do it:

# STEP 1: change the type_cateogry so "1a" becomes "1"

Extract the Numeric Portion of Type Category: Use regular expressions to isolate the numeric part of each Type category value.

```{r, echo=TRUE}
##Step 1: Load Data and Extract Numeric Category

# Used library calls:
#library(dplyr)
#library(readxl)

# Load data
data_trial02_trimmed <- read_excel("analysis/data/raw_data/data_trial02_trimmed.xlsx")

# Extract numeric part of type_category (e.g., "1a" becomes "1")
data_trial02_typesplit <- data_trial02_trimmed %>%
  mutate(numeric_category = as.numeric(gsub("[^0-9]", "", `type_category`)))

# View the typeslit dataset (optional)
#head(data_trial02_typesplit)

### You have now created a dataset "data_trial02_typesplit" with an extra column named "numeric_category" where the "type_category" has deleted the letter value in the type (i.e. "1a" becomes "1")
```

# Step 2: remove 0s but keep NAs

```{r, echo=TRUE}

# load libraries
#library(dplyr)
#library(ggplot2)
#library(cluster)
#library(readxl)

# Remove rows where actual_width is 0 (keeping NAs)
data_trial02_remove0 <- data_trial02_typesplit %>%
  filter(actual_width != 0 | is.na(actual_width))

```

# STEP 3: prepare the data

```{r, echo=TRUE}

# Load necessary libraries
library(dplyr)
library(ggplot2)
library(cluster)
library(readxl)

# Data preparation (keep only the "numeric_category" and "actual_width")
data_trial02_prep <- data_trial02_remove0 %>%
  select(numeric_category, actual_width) %>%
  mutate(numeric_category = as.factor(numeric_category))

# Normalize the actual_width (optional but recommended)
#data$actual_width <- scale(data$actual_width, center = TRUE, scale = TRUE)

# Convert categorical variable to numeric for clustering
data_trial02_numeric <- data_trial02_prep %>%
  mutate(numeric_category = as.numeric(as.character(numeric_category)))

# Remove rows with NA values for clustering
data_trial02_clustering <- data_trial02_numeric %>%
  filter(!is.na(numeric_category) & !is.na(actual_width))

## You have now created a dataset (data_trial02_clustering) ready for the cluster analysis, only containing the "numeric_category" and "actual_width" rows and cleaned them from 0s and NAs
```

# STEP 4: Perform a cluster analysis

To perform a cluster analysis between "numeric_category" and "actual_width" in your dataset (data_trial02_typesplit), you can follow these general steps in R:

1)Load Necessary Libraries: Ensure you have the necessary packages installed and loaded. Common packages for clustering include dplyr, ggplot2, and cluster.

2) Data Preparation: Prepare your data by ensuring that both numeric_category and actual_width are in the appropriate format for clustering.

3) Data Normalization: It can be beneficial to normalize your data, especially if the scale of actual_width differs significantly from numeric_category. (ONTE: I found that the normalization did only obscure the dataset)

4) Define how many clusters that are in your dataset

5) Clustering: Choose a clustering method, such as K-means or hierarchical clustering, to identify clusters.

6) Visualization: Visualize the clusters to see how actual_width relates to numeric_category.

```{r, echo=TRUE}
# install and load libraries

#install.packages("ggplot2")
#install.packages("cluster")
#install.packages("readxl")

library(dplyr)
library(ggplot2)
library(cluster)
library(readxl)

# Choose a number of clusters (e.g., k = 3 -> you can change this later, but you need to "add cluster assignments back to the original dataset" below)
set.seed(123)  # For reproducibility
k <- 3
kmeans_result <- kmeans(data_trial02_clustering[, c("numeric_category", "actual_width")], centers = k)

# Add cluster assignments back to the original dataset
# Ensure the cluster assignment only goes to rows without NAs
data_trial02_clustering$cluster <- NA  # Initialize the column with NAs
data_trial02_clustering$cluster[!is.na(data_trial02_clustering$numeric_category) & !is.na(data_trial02_clustering$actual_width)] <- as.factor(kmeans_result$cluster)

# Check that cluster assignments were added correctly
#summary(data_trial02_clustering$cluster)

```

OBS: Now you have made a dataset "data_trial02_clustering" that is without all the problems that the previous datasets had. Use this for the further analysis

# Check to see how many clusters that are in your dataset

To determine the optimal number of clusters for your dataset, you can use methods like the (1) elbow method or the (2) silhouette method. Here’s how to implement each of these methods in R:

1. Elbow Method:
This method involves plotting the total within-cluster sum of squares (WSS) for a range of cluster numbers and looking for the "elbow," where the rate of decrease slows, indicating a good cluster count.

```{r, echo=TRUE}
# Load necessary libraries
#library(dplyr)
#library(ggplot2)
#library(readxl)

# Elbow Method to find optimal number of clusters
wss <- vector("numeric", 10)  # Storage for within-cluster sum of squares

for (k in 1:10) {
  set.seed(123)  # For reproducibility
  kmeans_result <- kmeans(data_trial02_clustering[, c("numeric_category", "actual_width")], centers = k)
  wss[k] <- kmeans_result$tot.withinss
}

# Plot the elbow curve
plot(1:10, wss, type = "b", pch = 19, frame = FALSE,
     xlab = "Number of Clusters",
     ylab = "Total Within-Cluster Sum of Squares",
     main = "Elbow Method for Optimal Clusters")

```

The elbow plot helps determine the optimal number of clusters by plotting the total within-cluster sum of squares (WSS) for different numbers of clusters. Here's how to interpret it:

Interpreting the Elbow Plot:
Within-Cluster Sum of Squares (WSS): The y-axis represents WSS, which measures the compactness of clusters (lower values mean more compact clusters).

Elbow Point: As the number of clusters increases, WSS generally decreases because each additional cluster reduces the average distance between points and their assigned cluster center. However, there’s a point where adding more clusters no longer significantly improves compactness—this is the "elbow."

Optimal Number of Clusters:

Look for the "elbow" or bend in the plot where the WSS stops decreasing rapidly. This point indicates the optimal number of clusters, as adding more clusters beyond this point yields only minor improvements.
If the elbow is not clear, alternative methods like the silhouette plot may provide additional guidance.

Key Points to Remember
Distinct Elbow: A clear elbow usually indicates a strong clustering structure in the data.
Gradual Slope: If there's no obvious elbow, it may mean the data does not have a clear clustering structure, or that more advanced clustering techniques may be needed.

INTERPRETATION: I think my elbow is between 4 and 6. Try playing around with either 4, 5, or 6 clusters in the following

# Visualize the cluster plot

```{r, echo=TRUE}

# Set new cluster (Adjust k to 4, 5, or 6)

set.seed(123)  # For reproducibility
k <- 4
kmeans_result <- kmeans(data_trial02_clustering[, c("numeric_category", "actual_width")], centers = k)

# Add cluster assignments back to the dataset
data_trial02_clustering$cluster <- as.factor(kmeans_result$cluster)

# Visualize the clusters
ggplot(data_trial02_clustering, aes(x = numeric_category, y = actual_width, color = cluster)) +
  geom_point() +
  labs(title = "Cluster Analysis of Actual Width by Numeric Category",
       x = "Numeric Category",
       y = "Actual Width") +
  theme_minimal()

```
# How to interpret the cluster plot

A cluster plot visually shows the grouping of data points based on their similarity, as defined by the clustering algorithm. Here's how to interpret it:

Key Elements in the Cluster Plot

Data Points (Colored by Cluster):

Each point represents an observation, and its position on the x- and y-axes reflects its values for numeric_category and actual_width.
Points with the same color belong to the same cluster. The color grouping indicates which points are most similar according to the k-means algorithm.

Cluster Centroids (If Plotted):

Cluster centroids represent the center or "average" point of each cluster. These points are typically the mean of all data points within a cluster.
Although centroids aren't shown in the basic plot, adding them can help visualize the center of each cluster and identify how the clusters are spaced relative to each other.

How to Interpret the Plot

Cluster Composition:

Clusters group points that are similar in terms of numeric_category and actual_width. Points within the same cluster should be closer to each other compared to points in different clusters.
Check whether clusters are well-defined or overlapping. Overlapping clusters may indicate that some categories aren’t strongly distinct on these variables, or that the number of clusters (k) may need adjustment.

Cluster Size and Distribution:

If some clusters are much larger or denser than others, this can provide insights into the distribution of your data. Larger clusters may indicate categories with wider variability, while smaller, tightly grouped clusters may suggest high similarity within those clusters.

Outliers:

Isolated points within or outside clusters may be outliers or unique observations that don’t fit well within any group. These points may warrant further investigation to understand why they don’t cluster with others.

Distance Between Clusters:

Clusters with large gaps between them suggest well-separated groups, while closely spaced clusters may indicate that there’s not a strong separation in the data for these categories.

Next Steps:

Adjust the Number of Clusters: If the clusters don’t appear distinct or are overlapping significantly, consider using an alternative number of clusters and re-evaluate.

Analyze Cluster Characteristics: Beyond visual inspection, analyze the average characteristics within each cluster to gain deeper insights (e.g., average actual_width within each numeric_category cluster).

By studying the cluster plot, you gain insights into the natural groupings within your data and can assess whether the clustering captures meaningful patterns.

# Add Cluster Centroids to the plot

Adding cluster centroids to your cluster plot can help you visually identify the "center" of each cluster. Here’s how to modify your code to calculate and add these centroids to the plot:

First, calculate the centroids of each cluster based on the kmeans results.
Then, add these centroid points to the ggplot plot.

Explanation of the Code:

centroids <- as.data.frame(kmeans_result$centers): Extracts the cluster centers as a data frame, so they can be used in ggplot.

centroids$cluster <- as.factor(1:k): Adds a cluster column to the centroids data frame, labeling each centroid by its cluster number.

geom_point(data = centroids, aes(x = numeric_category, y = actual_width), color = "black", shape = 4, size = 5, stroke = 1.5): Adds the centroids to the plot. Here:

shape = 4 uses an "X" shape to distinguish centroids.

size = 5 and stroke = 1.5 make the centroids visually distinct.

This will add black "X" marks to represent the centroids of each cluster on your scatter plot.

```{r, echo=TRUE}

# Calculate centroids
centroids <- as.data.frame(kmeans_result$centers)  # Extract centers as a data frame
centroids$cluster <- as.factor(1:k)  # Label the clusters

# Visualize clusters with centroids
ggplot(data_trial02_clustering, aes(x = numeric_category, y = actual_width, color = cluster)) +
  geom_point(size = 3, alpha = 0.6) +
  geom_point(data = centroids, aes(x = numeric_category, y = actual_width), 
             color = "black", shape = 4, size = 5, stroke = 1.5) +  # Add centroids
  labs(title = "Cluster Analysis with Centroids",
       x = "Numeric Category",
       y = "Actual Width") +
  theme_minimal()

```
PRELIM interpretation: 

- I think I need to use 4 clusters.
- I must find out why there is no data in the "12" category of vessels
- I must see why there is only one datapoint in the "13" category of vessels

- For now, I think the clusterplot means that the category of vessels include the clusters identified by the colour, so vessel category 1 includes size clusters 1, 5, 2, 3, but vessel category 14 only includes size clusters 4. 

- I think the "centorids" describe that vessel category 4 (vertical vessels) have the center of size clusters 2 and 3. Vessel category 5 (closed vessels) has the center of size cluster 5. I think that vessel category 14 (bottles) have the center of size cluster 4. 

- I do not understand why size cluster 1 is hovering above vessel type 6 (tightly closed vessels) but the vessel types do not include this size cluster. Perhaps this is because I need to adjust the clusters to 4, or because the size clusters centroids are in the middle between vessel types 1-5 and type 10. 

# Add a legend to the final cluster plot

Explanation:

- main_plot: Contains your cluster plot with the cluster legend on the right.

- legend_table: A table of x-axis category descriptions.

- legend_plot: A plot version of legend_table using geom_text() to display each category with its description.

- plot_grid(): Combines the main_plot and legend_plot horizontally, placing the main plot on the left and the custom legend on the far right.

- This code will display the cluster plot with the x-axis legend appearing as a labeled table on the far right side. Adjust rel_widths to resize the plot and table as needed.

- plot.margin in both main_plot and legend_plot: Adjusted to reduce space between the plots and bring them closer.

- rel_widths = c(3, 1.2): Increased width allocated to the legend_plot to allow more space for the text.

This should ensure that the full text of each category is displayed. Adjust rel_widths and plot.margin further as needed for the best fit.

```{r, echo=TRUE}
## FINAL CLUSTER PLOT

#Install and load libraries
#install.packages("cowplot")    #For working with two legends in the plot
library(ggplot2)
library(cowplot)

# Main cluster plot with reduced right margin to bring it closer to the custom legend
main_plot <- ggplot(data_trial02_clustering, aes(x = numeric_category, y = actual_width, color = factor(cluster))) +
  geom_point(size = 3, alpha = 0.6) +
  geom_point(data = centroids, aes(x = numeric_category, y = actual_width), 
             color = "black", shape = 4, size = 5, stroke = 1.5) +  # Add centroids
  labs(title = "Cluster Analysis with Centroids",
       x = "Vessel type",
       y = "Vessel width (cm)",
       color = "Cluster") +
  scale_x_continuous(breaks = 1:15) +  # Set x-axis to display numbers 1-15
  scale_y_continuous(breaks = seq(0, max(data_trial02_clustering$actual_width, na.rm = TRUE), by = 10)) +  # Set y-axis to display every 10 cm
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.margin = margin(5, -90, 5, 5, "pt")  # Adjust right margin legend
  )

# Legend table with reduced left margin to bring it closer to the main plot
legend_table <- data.frame(
  Numeric_Category = 1:15,
  Description = c("Wide-open vessels", "Open vessels", "Closed horizontal-oval vessels", 
                  "Vertical vessels", "Closed vessels", "Tightly-closed vessels", 
                  "Open carinated vessels", "Wide-open carinated vessels", 
                  "Vertical-vertical oval vessels", "Closed-vertical oval vessels", 
                  "Tightly-closed vertical oval vessels", "Lids", 
                  "Flasks", "Bottles", "Tellem tripods")
)

# Convert the legend table to a plot with reduced left margin and smaller text size
legend_plot <- ggplot(legend_table, aes(x = "", y = Numeric_Category, label = paste(Numeric_Category, "=", Description))) +
  geom_text(hjust = 0, size = 3) +  # Reduced text size
  theme_void() +
  theme(
    plot.margin = margin(5, 5, 5, -10, "pt")  # Reduced left margin legend
  )

# Arrange the main plot and the custom legend side by side with adjusted width ratios
cowplot::plot_grid(main_plot, legend_plot, ncol = 2, rel_widths = c(3, 4))  # Adjust rel_width for legend plot if needed

```
OK! Now I got my plot to look nice with two legends! 
Perhaps I should try to do the same analysis only with 2 or 3 clusters (See elbow chart)?

PRELIM interpretation:

- Vessel category 5 (closed vessels) is the most numerous and also with a fair spread of all the 4 clusters of vessel width
- Vessel category 4 (vertical vessels) is the second most numerous also containing all the 4 clusters of width, but not so many from cluster 1
- Vessel category 1 (wide open vessels) and 2 (open vessels) are quite the same, but cat. 1 contains less small vessels and cat. 2 contains less larger vessels. As expected!
- Vessel category 7 (Open carinated vessels) are mainly clustering in cat. 3 and 2
- Vessel category 8 (wide-open carinated vessels) does not contain a lot of data, but is mainly clustering in cat. 2
- Vessel category 3 (closed horizontal oval vessels) are mainly clustering in cat. 4
- Vessel category 6 (tightly-closed vessels) are mainly clustering in category 4 and without any small cat. 3 sizes (as expected!)
- Vessel category 9 (vertical-vertical oval vessels) mainly cluster in the lower cat. 3 which is a surprice!
- Vessel category 10 (closed vertical oval vessels) has a nice spread of the clusters (surprise?), but mainly tails towards a higher width/cat. 1-2
- Vessel category 11 (tightly closed vertical oval vessels) does not contain a lot of data, but clusters in cat. 4
- Vessel category 12 are lids so I need to delete this category from the dataset
- Vessel category 13-14 (flasks and bottles) does not have a lot of data, but mainly cluster in the smaller cat. 3 as expected
- Vessel category 15 (Tellem tripods) mainly cluster in the lower cat. 3 as expected
- Perhaps the centroids do not help me a lot??

NEXT STEPS:

- Make a simple boxplot of how many data points you have for each vessel category
- Make a principal component analysis between the "width" and "vessel type" to see whether some types have smaller or larger sizes. Or perhaps try this with the square cm2?
- Make a principal component analysis of the "orifice" and the vessel type
- Make a principal component analysis of the height and the vessel type

- Prepare the "date" category in your excel sheet. Make all the dates numeric!

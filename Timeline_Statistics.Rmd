---
title: "INDPotteryChronology_Statistics"
author: "Soren Pedersen"
date: "20/09/2024"
output: html_document
---

###THIS IS THE MARKDOWN DOCUMENT OF THE STATISTICS OF THE IND POTTERY CHRONOLOGY
  #PhD thesis of Soren Feldborg


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Setup folder sturcture

```{r, echo=TRUE}

#install devtools

#install.packages("devtools")
library(devtools)

#install.packages("rrtools")
library(rrtools)

#You need the "remotes" package to install the "rrtools:BenMarwick" package 

#install.packages("remotes")
library(remotes)

remotes::install_github("benmarwick/rrtools")

#NOTE: I did install ALL updates

#devtools::install_github("benmarwick/rrtools")
---------------------------------------------------------------------------------------
  
#Create a new .Rproj -> very important not to have spaces, underscores or numbers in the folder name
  
#OBS: do not make a new .Rproj if you already have a project running -> skip to next step

#rrtools::use_compendium("C:/Users/Pedersen/Documents/R/PotteryChronologyIND")

#rrtools::use_compendium("C:/Users/Pedersen/Documents/R/RSeminar")


#Example: rrtools::use_compendium("C:/your/path/name/here/YourNewRProjectNameHere")

```

#Set up folder structure

This is to create folder "analysis" with sub-folder structure -> VERY USEFUL

The structure is made by Ben Marwick and is designated for archaeological writing and structure

```{r, echo=TRUE}
#Package that includes folder structure
library(rrtools)

#create folder -> creates the analysis folder and the structure
use_analysis()

#Do this below (pops-up when you execute use_analysis())

#Next, you need to:  ↓ ↓ ↓ ↓ 
#* Write your article/report/thesis, start at the paper.Rmd file
#* Add the citation style library file (csl) to replace the default provided here, see https://github.com/citation-style-language/
#* Add bibliographic details of cited items to the 'references.bib' file
#* For adding captions & cross-referencing in an Rmd, see https://bookdown.org/yihui/bookdown/
#* For adding citations & reference lists in an Rmd, see http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html
```

#Clean spreadsheet before loading into R

Cleaning a spreadsheet before loading it into R is an important step to ensure your data analysis is accurate and efficient. Here are some key steps you can follow to clean your spreadsheet:

1. Remove Unnecessary Data (done in excel sheet and r)
  - Delete Extra Rows/Columns: Remove any rows or columns that are not relevant to your analysis, such as empty rows or columns, headers that repeat, or any irrelevant metadata.
  - Trim Whitespace: Remove any leading or trailing spaces in your cells.

2. Standardize Formats (done in excel sheet)
  - Date Formats: Ensure all date entries are in a consistent format (e.g., YYYY-MM-DD).
  - Numeric Formats: Make sure numeric columns do not have any non-numeric characters (like commas or dollar signs).
  - Text Consistency: Standardize text entries (e.g., capitalization, spelling, etc.).

3. Handle Missing Values (done in r)
  - Identify Missing Values: Use functions to highlight or mark missing values.
  - Decide on a Strategy: Decide whether to remove rows with missing values, fill them in with a specific value (like the mean or median), or use other imputation techniques.

4. Correct Data Entry Errors (not done)
  - Identify Duplicates: Check for and remove duplicate rows if necessary.
  - Fix Inconsistencies: Look for typos or inconsistencies in categorical data (e.g., “male” vs. “Male”).

5. Transform Data if Necessary (not done)
  - Reformat Data Types: Ensure that each column has the correct data type (e.g., factors for categorical data, numeric for quantitative data).
  - Create New Columns: If necessary, create new columns for calculations or derived values.

6. Document Changes (done, see above parenthesis)
  - Keep a record of the changes made to your spreadsheet for transparency and reproducibility.

7. Save Your Cleaned Data (done, saved as .xlsx)
  - Save your cleaned spreadsheet in a compatible format (like CSV or Excel) for easy import into R.
  
8. I REMOVED THE 'SPECIAL' VESSEL TYPE CATEGORY AND REPLACED IT WITH '16a' INSTEAD IN THE 'data_tiral02_trimmed' DATA SET -> it was vessl number V559:    Ignore this data point when calculating vessel types
  
#Import excel file into a dataset and clean the dataset

Explanation of the Code:

- Loading Libraries: 
    Ensure that you have the required libraries installed and loaded.

- Reading Data: 
    The read_excel function is used to read the data from the Excel file.

- Data cleaning:
    Replace missing values with NAs
    Trim whitespaces in the excel sheet

- Saving Cleaned Data: 
    Optionally, save the cleaned dataset back to an Excel file using write.xlsx() from the openxlsx package (you'll need to install that package as well).

```{r, echo=TRUE}
# YOU CAN JUMP DIRECTLY TO STEP 1

### Load excel sheet into a dataset, trim whitespaces and replace missing rows with NAs

# Install necessary packages
#install.packages("readxl")
#install.packages("dplyr")
#install.packages("stringr")
#install.packages("tidyr")
#install.packages("openxlsx")

# Load necessary packages
#library(readxl)   # For reading Excel files
#library(dplyr)    # For data manipulation
#library(stringr)  # For string operations
#library(tidyr)    # For missing values operation
#library(openxlsx) # For writing Excel files

# Step 1: Load the Excel file
#data_trial02 <- read_excel("analysis/data/raw_data/timeline_data_trial02.xlsx")

# Step 2: View the initial structure of the data
#str(data_trial02)

# Step 3: Handle missing values
# Here, we're filling missing values with NA (default behavior)
# You can also replace them with specific values or remove rows.
#data_trial02 <- data_trial02 %>%
  #mutate(across(everything(), ~ replace_na(., NA)))  # Fill with NA (optional)

# Step 4: Trim whitespaces from all character columns
#data_trial02_trimmed <- data_trial02 %>%
  #mutate(across(where(is.character), ~ str_trim(.)))  # Trim whitespace

# View the cleaned data
#head(data_trial02_trimmed)

# Step 5: Save the cleaned data to a new Excel file
#write.xlsx(data_trial02_trimmed, "analysis/data/raw_data/data_trial02_trimmed.xlsx")

### Your dataset is now saved as "data_trial02_trimmed.xlsx" in the raw_data folder
```
# Change the type_cateogry so "1a" becomes "1"

OBS: From here I canged all the names of the datasets so they include "AW" (Actual Width) because I want to make the same cluster analysis with "height", "orifice" and "square cm2"

Extract the Numeric Portion of Type Category: Use regular expressions to isolate the numeric part of each Type category value.

```{r, echo=TRUE}
##Step 1: Load Data and Extract Numeric Category

# Used library calls:
library(readxl)   # For reading Excel files
library(dplyr)    # For data manipulation
library(stringr)  # For string operations
library(tidyr)    # For missing values operation
library(openxlsx) # For writing Excel files

# Load data
data_trial02_trimmedAW <- read_excel("analysis/data/raw_data/data_trial02_trimmed.xlsx")

# Extract numeric part of type_category (e.g., "1a" becomes "1")
data_trial02_typesplitAW <- data_trial02_trimmedAW %>%
  mutate(numeric_category = as.numeric(gsub("[^0-9]", "", `type_category`)))

# View the typeslit dataset (optional)
#head(data_trial02_typesplitAW)

```

You have now created a dataset "data_trial02_typesplitAW" with an extra column named "numeric_category" where the "type_category" has deleted the letter value in the type (i.e. "1a" becomes "1")

# Count how many data points there are under each 'vessel type' category

You can create a boxplot that shows the number of data points for each vessel type using the ggplot2 package in R. Below is an example code snippet to achieve this:

```{r, echo=TRUE}
# Install and load libraries
# install.packages("ggplot2")  # Uncomment if you haven't installed ggplot2
# install.packages("cowplot")  # Uncomment if you haven't installed cowplot
library(ggplot2)
library(cowplot)

# Create a data frame to count the number of data points for each vessel type
vessel_counts <- data.frame(table(data_trial02_typesplitAW$numeric_category))
colnames(vessel_counts) <- c("Vessel_Type", "Count")

# Create the boxplot with adjusted width
boxplot_plot <- ggplot(vessel_counts, aes(x = as.factor(Vessel_Type), y = Count)) +
  geom_boxplot(fill = "lightblue", outlier.color = "red") +
  labs(title = "Boxplot of Data Points per Vessel Type",
       x = "Vessel Type",
       y = "Number of Data Points") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for better visibility
    plot.margin = margin(10, 10, 10, 10)  # Adjust plot margins if needed
  )

# Legend table for vessel types
legend_table <- data.frame(
  Vessel_Type = 1:15,
  Description = c("Wide-open vessels", "Open vessels", "Closed horizontal-oval vessels", 
                  "Vertical vessels", "Closed vessels", "Tightly-closed vessels", 
                  "Open carinated vessels", "Wide-open carinated vessels", 
                  "Vertical-vertical oval vessels", "Closed-vertical oval vessels", 
                  "Tightly-closed vertical oval vessels", "Lids", 
                  "Flasks", "Bottles", "Tellem tripods")
)

# Convert the legend table to a plot with adjusted margins
legend_plot <- ggplot(legend_table, aes(x = "", y = Vessel_Type, label = paste(Vessel_Type, "=", Description))) +
  geom_text(hjust = 0, size = 3) +  # Reduced text size
  theme_void() +
  theme(
    plot.margin = margin(5, 100, 5, -60, "pt")  # Reduced right margin legend to move it closer to the plot
  )

# Arrange the boxplot and the legend side by side with adjusted widths
cowplot::plot_grid(boxplot_plot, legend_plot, ncol = 2, rel_widths = c(3, 3))  # Make the boxplot narrower adjusting rel_width

```
SO, the plot is not perfect, but I can adjust it later.

# PRELIM interpretation:

- Vessel category 5 (closed vessels) has by far the most data points -> interesting because it also has the most multi purpose function!!!
- 2nd most data point are vessel category 4 (vertical vessels)
- 3rd most data point are vessel category 2 (open vessels)
- 4th most data point are vessel category 7 (Open carinated vessels)
- 5th most data point are vessel category 1 (wide-open vessels)
- 6th most data point are vessel category 15 (Tellem tripods)
- 7th and 8th most data point are vessel category 3 (closed horizontal-oval vessels) and 10 (closed vertical-oval vessels)
- 9th most data point are vessel category 6 (tightly-closed vessels)
- 10th most data point are vessel category 8 (wide-open carinated vessels)
- 11th most data point are vessel category 9 (Vertical vertical-oval vessels)
- 12th most data point are vessel category 11 (tightly-closed vertical oval vessels)
- 13th most data point are vessel category 14 (bottles)
- 14th most data point are vessel category 13 (flasks)
- vessel category 12 is left out because there are no data points (lids)

- There is actually a correlation between how "multi-purpose" a vessel is and the amount of data points I have collected. The "closed vessels", "vertical vessels" and the "open vessels" are the three categories you can describe as the most multi-purpose!

# Make cluster analysis of the main "actural_width" category dependent on "type_category"

To analyze clusters of Actual width within each numeric category of the Type category (ignoring the letter part, such as 1a, 1b, 1c grouped as 1), we can split the data by the numeric portion of the Type category and then perform clustering on Actual width measurements within each group. Here’s how to do it:

# Remove 0s but keep NAs of 'actual width' column

```{r, echo=TRUE}

# load libraries
library(dplyr)
library(ggplot2)
library(cluster)
library(readxl)

# Remove rows where actual_width is 0 (keeping NAs)
data_trial02_remove0AW <- data_trial02_typesplitAW %>%
  filter(actual_width != 0 | is.na(actual_width))

```

# Prepare the data of the actual width column

```{r, echo=TRUE}

# Load necessary libraries
library(dplyr)
library(ggplot2)
library(cluster)
library(readxl)

# Data preparation (keep only the "numeric_category" and "actual_width" columns)
data_trial02_prepAW <- data_trial02_remove0AW %>%
  select(numeric_category, actual_width) %>%
  mutate(numeric_category = as.factor(numeric_category))

# Normalize the actual_width (optional but recommended, my data looks very strange if I do this)
#data$actual_width <- scale(data$actual_width, center = TRUE, scale = TRUE)

# Convert categorical variable to numeric for clustering
data_trial02_numericAW <- data_trial02_prepAW %>%
  mutate(numeric_category = as.numeric(as.character(numeric_category)))

# Remove rows with NA values for clustering
data_trial02_clusteringAW <- data_trial02_numericAW %>%
  filter(!is.na(numeric_category) & !is.na(actual_width))

```

You have now created a dataset (data_trial02_clusteringAW) ready for the cluster analysis, only containing the "numeric_category" and "actual_width" rows and cleaned them from 0s and NAs

# STEP 4: Perform a cluster analysis

To perform a cluster analysis between "numeric_category" and "actual_width" in your dataset (data_trial02_typesplitAW), you can follow these general steps in R:

1)Load Necessary Libraries: Ensure you have the necessary packages installed and loaded. Common packages for clustering include dplyr, ggplot2, and cluster.

2) Data Preparation: Prepare your data by ensuring that both numeric_category and actual_width are in the appropriate format for clustering.

3) Data Normalization: It can be beneficial to normalize your data, especially if the scale of actual_width differs significantly from numeric_category. (ONTE: I found that the normalization did only obscure the dataset)

4) Define how many clusters that are in your dataset

5) Clustering: Choose a clustering method, such as K-means or hierarchical clustering, to identify clusters.

6) Visualization: Visualize the clusters to see how actual_width relates to numeric_category.

```{r, echo=TRUE}
# install and load libraries

#install.packages("ggplot2")
#install.packages("cluster")
#install.packages("readxl")

library(dplyr)
library(ggplot2)
library(cluster)
library(readxl)

# Choose a number of clusters (e.g., k = 3 -> you can change this later, but you need to "add cluster assignments back to the original dataset" below)
set.seed(123)  # For reproducibility
k <- 3
kmeans_resultAW <- kmeans(data_trial02_clusteringAW[, c("numeric_category", "actual_width")], centers = k)

# Add cluster assignments back to the original dataset
# Ensure the cluster assignment only goes to rows without NAs
data_trial02_clusteringAW$cluster <- NA  # Initialize the column with NAs
data_trial02_clusteringAW$cluster[!is.na(data_trial02_clusteringAW$numeric_category) & !is.na(data_trial02_clusteringAW$actual_width)] <- as.factor(kmeans_resultAW$cluster)

# Check that cluster assignments were added correctly
summary(data_trial02_clusteringAW$cluster)

```

OBS: Now you have made a dataset "data_trial02_clusteringAW" that is without all the problems that the previous datasets I had. Use this for the further analysis

# Check to see how many clusters that are in your dataset

To determine the optimal number of clusters for your dataset, you can use methods like the (1) elbow method or the (2) silhouette method. Here’s how to implement each of these methods in R:

1. Elbow Method:
This method involves plotting the total within-cluster sum of squares (WSS) for a range of cluster numbers and looking for the "elbow," where the rate of decrease slows, indicating a good cluster count.

```{r, echo=TRUE}
# Load necessary libraries
#library(dplyr)
#library(ggplot2)
#library(readxl)

# Elbow Method to find optimal number of clusters
wssAW <- vector("numeric", 10)  # Storage for within-cluster sum of squares

for (k in 1:10) {
  set.seed(123)  # For reproducibility
  kmeans_resultAW <- kmeans(data_trial02_clusteringAW[, c("numeric_category", "actual_width")], centers = k)
  wssAW[k] <- kmeans_resultAW$tot.withinss
}

# Plot the elbow curve
plot(1:10, wssAW, type = "b", pch = 19, frame = FALSE,
     xlab = "Number of Clusters",
     ylab = "Total Within-Cluster Sum of Squares",
     main = "Elbow Method for Optimal Clusters")

```

The elbow plot helps determine the optimal number of clusters by plotting the total within-cluster sum of squares (WSS) for different numbers of clusters. Here's how to interpret it:

Interpreting the Elbow Plot:
Within-Cluster Sum of Squares (WSS): The y-axis represents WSS, which measures the compactness of clusters (lower values mean more compact clusters).

Elbow Point: As the number of clusters increases, WSS generally decreases because each additional cluster reduces the average distance between points and their assigned cluster center. However, there’s a point where adding more clusters no longer significantly improves compactness—this is the "elbow."

Optimal Number of Clusters:

Look for the "elbow" or bend in the plot where the WSS stops decreasing rapidly. This point indicates the optimal number of clusters, as adding more clusters beyond this point yields only minor improvements.
If the elbow is not clear, alternative methods like the silhouette plot may provide additional guidance.

Key Points to Remember
Distinct Elbow: A clear elbow usually indicates a strong clustering structure in the data.
Gradual Slope: If there's no obvious elbow, it may mean the data does not have a clear clustering structure, or that more advanced clustering techniques may be needed.

INTERPRETATION: I think my elbow is between 4 and 6. Try playing around with either 4, 5, or 6 clusters in the following

# Visualize the cluster plot with automatic optimal amount of clusters

```{r, echo=TRUE}

# Install and load necessary libraries
# install.packages("factoextra")  # For visualizing clusters and optimal number

library(ggplot2)
library(factoextra)

# Calculate WCSS for different numbers of clusters (1 to 15)
wcssAW <- numeric()
for (i in 1:15) {
  set.seed(123)
  kmeans_resultAW <- kmeans(data_trial02_clusteringAW[, c("numeric_category", "actual_width")], centers = i)
  wcssAW[i] <- sum(kmeans_resultAW$tot.withinss)
}

# Calculate the optimal number of clusters using the "elbow method" by finding the maximum drop
wcss_diffsAW <- diff(wcssAW)  # First derivative (differences between consecutive WCSS values)
optimal_clustersAW <- which.max(abs(diff(wcss_diffsAW))) + 1  # Find the biggest drop in WCSS

# Elbow plot with the optimal number of clusters marked
elbow_plotAW <- ggplot(data = data.frame(Clusters = 1:15, WCSSAW = wcssAW), aes(x = Clusters, y = WCSSAW)) +
  geom_point(size = 4) +
  geom_line(linewidth = 1) +
  labs(title = "Elbow Plot for Optimal Clusters of 'actual width'",
       x = "Number of Clusters",
       y = "Within-Cluster Sum of Squares (WCSS)") +
  theme_minimal() +
  geom_vline(xintercept = optimal_clustersAW, linetype = "dashed", color = "red", size = 1) +
  annotate("text", x = optimal_clustersAW, y = max(wcssAW), label = paste("Optimal Clusters =", optimal_clustersAW), 
           color = "red", vjust = -1, size = 4)

# Display the plot
print(elbow_plotAW)

```
So my optimal amount of clusters are 2!

# Visualize the cluster plot

```{r, echo=TRUE}

# Set new cluster (Adjust k to 2)

set.seed(123)  # For reproducibility
kAW <- 2
kmeans_resultAW <- kmeans(data_trial02_clusteringAW[, c("numeric_category", "actual_width")], centers = kAW)

# Add cluster assignments back to the dataset
data_trial02_clusteringAW$cluster <- as.factor(kmeans_resultAW$cluster)

# Visualize the clusters
ggplot(data_trial02_clusteringAW, aes(x = numeric_category, y = actual_width, color = cluster)) +
  geom_point() +
  labs(title = "Cluster Analysis of 'actual width' by 'vessel type'",
       x = "Vessel type",
       y = "Actual width (cm)") +
  theme_minimal()

```
# How to interpret the cluster plot

A cluster plot visually shows the grouping of data points based on their similarity, as defined by the clustering algorithm. Here's how to interpret it:

Key Elements in the Cluster Plot

Data Points (Colored by Cluster):

Each point represents an observation, and its position on the x- and y-axes reflects its values for numeric_category and actual_width.
Points with the same color belong to the same cluster. The color grouping indicates which points are most similar according to the k-means algorithm.

Cluster Centroids (If Plotted):

Cluster centroids represent the center or "average" point of each cluster. These points are typically the mean of all data points within a cluster.
Although centroids aren't shown in the basic plot, adding them can help visualize the center of each cluster and identify how the clusters are spaced relative to each other.

How to Interpret the Plot

Cluster Composition:

Clusters group points that are similar in terms of numeric_category and actual_width. Points within the same cluster should be closer to each other compared to points in different clusters.
Check whether clusters are well-defined or overlapping. Overlapping clusters may indicate that some categories aren’t strongly distinct on these variables, or that the number of clusters (k) may need adjustment.

Cluster Size and Distribution:

If some clusters are much larger or denser than others, this can provide insights into the distribution of your data. Larger clusters may indicate categories with wider variability, while smaller, tightly grouped clusters may suggest high similarity within those clusters.

Outliers:

Isolated points within or outside clusters may be outliers or unique observations that don’t fit well within any group. These points may warrant further investigation to understand why they don’t cluster with others.

Distance Between Clusters:

Clusters with large gaps between them suggest well-separated groups, while closely spaced clusters may indicate that there’s not a strong separation in the data for these categories.

Next Steps:

Adjust the Number of Clusters: If the clusters don’t appear distinct or are overlapping significantly, consider using an alternative number of clusters and re-evaluate.

Analyze Cluster Characteristics: Beyond visual inspection, analyze the average characteristics within each cluster to gain deeper insights (e.g., average actual_width within each numeric_category cluster).

By studying the cluster plot, you gain insights into the natural groupings within your data and can assess whether the clustering captures meaningful patterns.

# Add Cluster Centroids to the plot

Adding cluster centroids to your cluster plot can help you visually identify the "center" of each cluster. Here’s how to modify your code to calculate and add these centroids to the plot:

First, calculate the centroids of each cluster based on the kmeans results.
Then, add these centroid points to the ggplot plot.

Explanation of the Code:

centroids <- as.data.frame(kmeans_result$centers): Extracts the cluster centers as a data frame, so they can be used in ggplot.

centroids$cluster <- as.factor(1:k): Adds a cluster column to the centroids data frame, labeling each centroid by its cluster number.

geom_point(data = centroids, aes(x = numeric_category, y = actual_width), color = "black", shape = 4, size = 5, stroke = 1.5): Adds the centroids to the plot. Here:

shape = 4 uses an "X" shape to distinguish centroids.

size = 5 and stroke = 1.5 make the centroids visually distinct.

This will add black "X" marks to represent the centroids of each cluster on your scatter plot.

```{r, echo=TRUE}

# Calculate centroids
centroidsAW <- as.data.frame(kmeans_resultAW$centers)  # Extract centers as a data frame
centroidsAW$cluster <- as.factor(1:k)  # Label the clusters

# Visualize clusters with centroids
ggplot(data_trial02_clusteringAW, aes(x = numeric_category, y = actual_width, color = cluster)) +
  geom_point(size = 3, alpha = 0.6) +
  geom_point(data = centroidsAW, aes(x = numeric_category, y = actual_width), 
             color = "black", shape = 4, size = 5, stroke = 1.5) +  # Add centroids
  labs(title = "Cluster Analysis of 'actual width' with Centroids",
       x = "Numeric Category",
       y = "Actual Width") +
  theme_minimal()

```
PRELIM interpretation: 

- I have 2 clusters of 'actual width'
- All my vessel types include cluster 2
- Vessel types 9, 13 and 14 only have cluster 2 and not cluster 1
- The centroids are centered around vessel type 5 (closed vessels). Is this perhaps because this vessel category contains most data points, or is it perhaps because it is the most multi-purpose vessel -> i.e. that it is the "median" of the data set?

# Add a legend to the final cluster plot

Explanation:

- main_plot: Contains your cluster plot with the cluster legend on the right.

- legend_table: A table of x-axis category descriptions.

- legend_plot: A plot version of legend_table using geom_text() to display each category with its description.

- plot_grid(): Combines the main_plot and legend_plot horizontally, placing the main plot on the left and the custom legend on the far right.

- This code will display the cluster plot with the x-axis legend appearing as a labeled table on the far right side. Adjust rel_widths to resize the plot and table as needed.

- plot.margin in both main_plot and legend_plot: Adjusted to reduce space between the plots and bring them closer.

- rel_widths = c(3, 1.2): Increased width allocated to the legend_plot to allow more space for the text.

This should ensure that the full text of each category is displayed. Adjust rel_widths and plot.margin further as needed for the best fit.

```{r, echo=TRUE}
## FINAL CLUSTER PLOT

#Install and load libraries
#install.packages("cowplot")    #For working with two legends in the plot
library(ggplot2)
library(cowplot)
library(dplyr)

# Add a new column to indicate the predominant cluster for each vessel type
data_trial02_clusteringAW <- data_trial02_clusteringAW %>%
  group_by(numeric_category) %>%
  mutate(predominant_cluster = ifelse(sum(cluster == 1) >= sum(cluster == 2), "Cluster 1", "Cluster 2"))

# Main cluster plot with reduced right margin to bring it closer to the custom legend
main_plotAW <- ggplot(data_trial02_clusteringAW, aes(x = numeric_category, y = actual_width, color = factor(cluster), shape = predominant_cluster)) +
  geom_point(size = 3, alpha = 0.6) +
  geom_point(data = centroidsAW, aes(x = numeric_category, y = actual_width), 
             color = "black", shape = 4, size = 5, stroke = 1.5) +  # Add centroids
  labs(title = "Cluster Analysis of 'actual width' with Centroids",
       x = "Vessel type",
       y = "Vessel width (cm)",
       color = "Cluster",
       shape = "Predominant Cluster") +
  scale_x_continuous(breaks = 1:15) +  # Set x-axis to display numbers 1-15
  scale_y_continuous(breaks = seq(0, max(data_trial02_clusteringAW$actual_width, na.rm = TRUE), by = 10)) +  # Set y-axis to display every 10 cm
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.margin = margin(5, -90, 5, 5, "pt")  # Adjust right margin legend
  )

# Main cluster plot with reduced right margin to bring it closer to the custom legend
main_plotAW <- ggplot(data_trial02_clusteringAW, aes(x = numeric_category, y = actual_width, color = factor(cluster))) +
  geom_point(size = 3, alpha = 0.6) +
  geom_point(data = centroidsAW, aes(x = numeric_category, y = actual_width), 
             color = "black", shape = 4, size = 5, stroke = 1.5) +  # Add centroids
  labs(title = "Cluster Analysis of 'actual width' with Centroids",
       x = "Vessel type",
       y = "Vessel width (cm)",
       color = "Cluster") +
  scale_x_continuous(breaks = 1:15) +  # Set x-axis to display numbers 1-15
  scale_y_continuous(breaks = seq(0, max(data_trial02_clusteringAW$actual_width, na.rm = TRUE), by = 10)) +  # Set y-axis to display every 10 cm
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.margin = margin(5, -90, 5, 5, "pt")  # Adjust right margin legend
  )

# Calculate min and max for each cluster to insert in the legend (Change this if you have more than 2 clusters)
cluster1AW_min <- min(data_trial02_clusteringAW$actual_width[data_trial02_clusteringAW$cluster == 1], na.rm = TRUE)
cluster1AW_max <- max(data_trial02_clusteringAW$actual_width[data_trial02_clusteringAW$cluster == 1], na.rm = TRUE)
cluster2AW_min <- min(data_trial02_clusteringAW$actual_width[data_trial02_clusteringAW$cluster == 2], na.rm = TRUE)
cluster2AW_max <- max(data_trial02_clusteringAW$actual_width[data_trial02_clusteringAW$cluster == 2], na.rm = TRUE)

# Replace placeholders with actual values in the legend (Change this if you have more than 2 clusters)
main_plotAW <- main_plotAW + 
  labs(color = paste("Cluster\n1:", cluster1AW_min, "-", cluster1AW_max, "cm\n2:", cluster2AW_min, "-", cluster2AW_max, "cm"))

# Legend table with reduced left margin to bring it closer to the main plot
legend_tableAW <- data.frame(
  Numeric_Category = 1:15,
  Description = c("Wide-open vessels", "Open vessels", "Closed horizontal-oval vessels", 
                  "Vertical vessels", "Closed vessels", "Tightly-closed vessels", 
                  "Open carinated vessels", "Wide-open carinated vessels", 
                  "Vertical-vertical oval vessels", "Closed-vertical oval vessels", 
                  "Tightly-closed vertical oval vessels", "Lids", 
                  "Flasks", "Bottles", "Tellem tripods")
)

# Convert the legend table to a plot with reduced left margin and smaller text size
legend_plotAW <- ggplot(legend_tableAW, aes(x = "", y = Numeric_Category, label = paste(Numeric_Category, "=", Description))) +
  geom_text(hjust = 0, size = 3) +  # Reduced text size
  theme_void() +
  theme(
    plot.margin = margin(5, 5, 5, -10, "pt")  # Reduced left margin legend
  )

# Arrange the main plot and the custom legend side by side with adjusted width ratios
cowplot::plot_grid(main_plotAW, legend_plotAW, ncol = 2, rel_widths = c(3, 4))  # Adjust rel_width for legend plot if needed

```
OK! Now I got my plot to look nice with two legends and the range of my clusters! 

#PRELIM interpretation:

OBS: This interpretation was made with 2 clusters (as is the optimal amount of clusters for "actual width")

- Cluster 1 is between 28 - 97.6 cm
- Cluster 2 is between 4.8 - 27.6 cm
- All my vessel types have cluster 2
- Vessel types 9, 13, and 14 does NOT have cluster 1
- The two centroids are centered around vessel type 5 (closed vessels). Is this because it contains the most data points, or is it because it is the vessel type that is best represented in both clusters?
- Vessel type 5 (closed vessels) has the largest width (surprisingly)
- Vessel type 9 (Vertical vertical-oval vessels) has the smallest width (These are often the "cup"-category also!)
- Vessels 1-5, 7, 9, 11, 13, 14, and 15 is predominant in cluster 2 (small size cluster)
- Vessels 6 (tightly-closed vessels), 8 (wide-open carinated vessels), and 10 (closed vertical-oval vessels) are predominant in cluster 1 (large size cluster)
- The vessels that cluster in the large size cluster are the storage vessels (for liquids) (cat. 6), serving or frying vessels (cat. 8), and the large storage jars (cat. 10) -> as suspected!!

 
#PRELIM interpretation (OLD01):

OBS: This interpretation was made using 4 clusters!

- Vessel category 5 (closed vessels) is the most numerous and also with a fair spread of all the 4 clusters of vessel width
- Vessel category 4 (vertical vessels) is the second most numerous also containing all the 4 clusters of width, but not so many from cluster 1
- Vessel category 1 (wide open vessels) and 2 (open vessels) are quite the same, but cat. 1 contains less small vessels and cat. 2 contains less larger vessels. As expected!
- Vessel category 7 (Open carinated vessels) are mainly clustering in cat. 3 and 2
- Vessel category 8 (wide-open carinated vessels) does not contain a lot of data, but is mainly clustering in cat. 2
- Vessel category 3 (closed horizontal oval vessels) are mainly clustering in cat. 4
- Vessel category 6 (tightly-closed vessels) are mainly clustering in category 4 and without any small cat. 3 sizes (as expected!)
- Vessel category 9 (vertical-vertical oval vessels) mainly cluster in the lower cat. 3 which is a surprice!
- Vessel category 10 (closed vertical oval vessels) has a nice spread of the clusters (surprise?), but mainly tails towards a higher width/cat. 1-2
- Vessel category 11 (tightly closed vertical oval vessels) does not contain a lot of data, but clusters in cat. 4
- Vessel category 12 are lids so I need to delete this category from the dataset
- Vessel category 13-14 (flasks and bottles) does not have a lot of data, but mainly cluster in the smaller cat. 3 as expected
- Vessel category 15 (Tellem tripods) mainly cluster in the lower cat. 3 as expected
- Perhaps the centroids do not help me a lot??

#NEXT STEPS:

- Make a cluster analysis of "height"
- Make a cluster analysis of "orifice diameter"
- Make a cluster analysis of "square cm2"

- Make a simple boxplot of how many data points you have for each vessel category (DONE)
- Make a principal component analysis between the "width" and "vessel type" to see whether some types have smaller or larger sizes. Or perhaps try this with the square cm2?
- Make a principal component analysis of the "orifice" and the vessel type
- Make a principal component analysis of the height and the vessel type

- Prepare the "date" category in your excel sheet. Make all the dates numeric!

# Making a cluster analysis of 'orifice diameter', 'width', and 'height'

(chatgpt): For cluster analysis on your archaeological ceramics, I would suggest focusing on all three size variables you mentioned: orifice diameter, total width, and total height. These data points will give you a well-rounded representation of vessel size. Using all three variables for clustering will allow you to identify patterns based on the overall size and shape of the vessels, which could correspond to functional or stylistic categories.

So, your key variables for clustering would be:

- Orifice diameter
- Total width
- Total height

You can standardize these variables if they are on different scales before running the cluster analysis to ensure fair comparison.

It performs hierarchical and k-means clustering using your size measurements.

# Cluster analysis of 'actual width' and 'orifice diameter'

First, I will make an elbow plot of 'actual width' and 'orifice diameter' to determine the optimal number of clusters

```{r, echo=TRUE}

# Install and load necessary libraries
# install.packages("readxl")    # For reading Excel files
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("factoextra") # For visualizing clusters
# install.packages("cluster")

library(readxl)
library(dplyr)
library(ggplot2)
library(factoextra)
library(cluster)

# Load your dataset from an Excel file
# Replace 'your_file.xlsx' with the actual path to your file
ceramics_data <- read_excel("analysis/data/raw_data/data_trial02_trimmed.xlsx")

# Ensure your Excel file has columns: actual_diameter, actual_width, actual_height
# Check the first few rows of your data
#head(ceramics_data)

# Extract numeric part of type_category (e.g., "1a" becomes "1")
ceramics_data_typesplit <- ceramics_data %>%
  mutate(numeric_category = as.numeric(gsub("[^0-9]", "", `type_category`)))

# Select the relevant columns for clustering
ceramics_subset <- ceramics_data_typesplit %>%
  select(actual_diameter, actual_width, actual_height, numeric_category) %>%
  na.omit()  # Remove rows with missing values

# Standardize the data (important when variables have different units)
ceramics_scaled <- scale(ceramics_subset)
```

#Elbow plot of 'actual width' and 'orifice diameter'

The plot determines the optimal amount of clusters. To automatically determine the optimal number of clusters using the elbow method, you can use a combination of the elbow plot and the "Kneedle" algorithm, which can help identify the point where the slope of the WSS decreases sharply. However, R does not have a built-in function for this, but we can implement a simple method to find it.

Automatic Optimal 

- k Calculation: The code uses the second derivative of the WSS to identify the optimal number of clusters automatically.
- Elbow Plot with Dashed Line: The elbow plot includes a dashed line indicating the optimal k value.
- Dendrogram: Hierarchical clustering is performed, and the dendrogram is plotted, showing the cut for the optimal number of clusters.

Here's the complete R code that calculates the WSS for different values of k, plots the elbow plot, and automatically determines the optimal number of clusters based on the change in WSS:

```{r, echo=TRUE}
# 1. Elbow Plot to Determine Optimal Number of Clusters

# Set a range for k
wss <- numeric(10)  # Pre-allocate a vector for WSS values

for (k in 1:10) {
  kmeans_result <- kmeans(ceramics_scaled, centers = k)
  wss[k] <- kmeans_result$tot.withinss  # Store the WSS for each k
}

# Calculate the rate of change in WSS to find the elbow point
delta_wss <- diff(wss)  # Change in WSS
delta2_wss <- diff(delta_wss)  # Second derivative to find the elbow

# Find the optimal number of clusters where the second derivative is maximum
optimal_k <- which.max(delta2_wss) + 2  # Adding 2 because diff reduces the length by 1

# Create the elbow plot
elbow_plot <- ggplot(data.frame(k = 1:10, WSS = wss), aes(x = k, y = WSS)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = wss[optimal_k], linetype = "dashed", color = "red") +  # Add red dashed line
  labs(title = "Elbow Plot for K-means Clustering of 'actual width' and 'orifice diameter'",
       x = "Number of Clusters (k)",
       y = "Total Within-Cluster Sum of Squares (WSS)") +
  theme_minimal() +
  annotate("text", x = optimal_k + 0.5, y = wss[optimal_k], 
           label = paste("Optimal k =", optimal_k), color = "red", vjust = -0.5)

# Print the elbow plot
print(elbow_plot)
```
So, my optimal number of clusters for 'actual width' and 'orifice diameter' is 3!

# Hierarchial clustering of 'actual width' and 'orifice diameter'

```{r, echo=TRUE}
# 1. Hierarchical Clustering

# Compute the distance matrix
dist_matrix <- dist(ceramics_scaled, method = "euclidean")

# Perform hierarchical clustering
hc <- hclust(dist_matrix, method = "ward.D2")

# Plot the dendrogram   (RUN TOGETHER WITH CHUNK BELOW!!!)
plot(hc, main = "Hierarchical Clustering Dendrogram", xlab = "", sub = "", cex = 0.6)

# Choose the number of clusters (k) by cutting the dendrogram
k <- 3  # You can experiment with different values for k (Elbow plot = 3)
rect.hclust(hc, k = k, border = 2:4)  # Visualize the cut on the dendrogram
```
PRELIM interpretation:

I need to make the data points clearer in the bottom row!

I think it means that I have 3 clusters that start clustering around 20 cm in height? Further interpretation will be conducted when I have cleaned the bottom row

I do not understand what happens when I normalize the data, but I see that my clusters change when I do not do it. My data looks quite strange when I normalize it, so I'm not sure what is the best??

# K-means clustering

```{r, echo=TRUE}

# 2. K-means Clustering

# Perform k-means clustering with the chosen number of clusters
set.seed(123)  # For reproducibility
kmeans_result <- kmeans(ceramics_scaled, centers = k)

# Add the cluster results to the original data
ceramics_data_typesplit$cluster <- kmeans_result$cluster

# Visualize the clusters using the first two dimensions
fviz_cluster(kmeans_result, data = ceramics_scaled, geom = "point", ellipse = TRUE) +
  labs(title = "K-means Clustering of Ceramics")
```
PRELIM interpretation:

1- My Dim1 (x-axis) conmtrols 83.8% of the clustering variable, and my Dim2 controls 14.9% of the clustering variable. 
2- I have only changed V559 to "16a" and now my dataset looks completely different -> Dim1(62.9%) Dim2(27%) <- I think that my data should not change so much just because I canged one entry in the spreadsheet??

I will continue with these changes for now..

```{r, echo=TRUE}
library(cowplot)

# 3. Visualize the clusters with clusters as shapes and vessel types as colors
main_plot <- ggplot(ceramics_data_typesplit, aes(x = actual_diameter, y = actual_width, shape = factor(cluster), color = factor(numeric_category))) +
  geom_point(size = 3) +
  labs(title = "Cluster Analysis of Vessel Sizes",
       x = "Orifice Diameter (cm)",
       y = "Total Width (cm)",
       shape = "Cluster",     # Clusters represented by shapes
       color = "Vessel Type") +  # Vessel types represented by colors
  theme_minimal() +
  theme(
    legend.position = "right",
    legend.box = "horizontal"  # Arrange the legends horizontally
  )

# Extract the legends for clusters and vessel types
cluster_legend <- cowplot::get_legend(main_plot + guides(color = "none"))  # Remove vessel type legend
vessel_type_legend <- cowplot::get_legend(main_plot + guides(shape = "none"))  # Remove cluster legend

# Combine the main plot and both legends side by side
final_plot <- cowplot::plot_grid(main_plot + theme(legend.position = "none"), 
                                 cowplot::plot_grid(cluster_legend, vessel_type_legend, ncol = 1), 
                                 rel_widths = c(4, 1))  # Adjust relative widths

# Display the final plot
print(final_plot)
```
PRELIM interpretation:

This looks much better than my previous cluster analysis! 


# Cluster analysis of 'width' and 'height'

```{r, echo=TRUE}
library(readxl)
library(dplyr)
library(ggplot2)
library(factoextra)
library(cluster)

# Load your dataset from an Excel file
ceramics_data <- read_excel("analysis/data/raw_data/data_trial02_trimmed.xlsx")

# Ensure your Excel file has columns: actual_diameter, actual_width
# Check the first few rows of your data
head(ceramics_data)

# Select the relevant columns for clustering (Diameter and Width)
ceramics_subset <- ceramics_data %>%
  select(actual_diameter, actual_width) %>%
  na.omit()  # Remove rows with missing values

# Standardize the data (important when variables have different units)
ceramics_scaled <- scale(ceramics_subset)

# 1. Elbow Plot to Determine Optimal Number of Clusters

# Set a range for k
wss <- numeric(10)  # Preallocate a vector for WSS values

for (k in 1:10) {
  kmeans_result <- kmeans(ceramics_scaled, centers = k)
  wss[k] <- kmeans_result$tot.withinss  # Store the WSS for each k
}

# Calculate the rate of change in WSS to find the elbow point
delta_wss <- diff(wss)  # Change in WSS
delta2_wss <- diff(delta_wss)  # Second derivative to find the elbow

# Find the optimal number of clusters where the second derivative is maximum
optimal_k <- which.max(delta2_wss) + 2  # Adding 2 because diff reduces the length by 1

# Create the elbow plot
elbow_plot <- ggplot(data.frame(k = 1:10, WSS = wss), aes(x = k, y = WSS)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = wss[optimal_k], linetype = "dashed", color = "red") +  # Add red dashed line
  labs(title = "Elbow Plot for K-means Clustering",
       x = "Number of Clusters (k)",
       y = "Total Within-Cluster Sum of Squares (WSS)") +
  theme_minimal() +
  annotate("text", x = optimal_k + 0.5, y = wss[optimal_k], 
           label = paste("Optimal k =", optimal_k), color = "red", vjust = -0.5)

# Print the elbow plot
print(elbow_plot)

# 2. Hierarchical Clustering

# Compute the distance matrix
dist_matrix <- dist(ceramics_scaled, method = "euclidean")

# Perform hierarchical clustering
hc <- hclust(dist_matrix, method = "ward.D2")

# Plot the dendrogram
plot(hc, main = "Hierarchical Clustering Dendrogram", xlab = "", sub = "", cex = 0.6)

# Choose the number of clusters (k) by cutting the dendrogram
rect.hclust(hc, k = optimal_k, border = 2:4)  # Visualize the cut on the dendrogram

# 3. K-means Clustering

# Perform k-means clustering with the determined number of clusters
set.seed(123)  # For reproducibility
kmeans_result <- kmeans(ceramics_scaled, centers = optimal_k)

# Add the cluster results to the original data
ceramics_data$cluster <- kmeans_result$cluster

# Visualize the clusters using the first two dimensions
fviz_cluster(kmeans_result, data = ceramics_scaled, geom = "point", ellipse = TRUE) +
  labs(title = "K-means Clustering of Ceramics")

# Visualize the clusters by diameter and width variables
ggplot(ceramics_data, aes(x = actual_diameter, y = actual_width, color = factor(cluster))) +
  geom_point(size = 3) +
  labs(title = "Cluster Analysis of Vessel Sizes",
       x = "Orifice Diameter (cm)",
       y = "Total Width (cm)",
       color = "Cluster") +
  theme_minimal()

# Optional: Output the cluster result
table(ceramics_data$cluster)


```
